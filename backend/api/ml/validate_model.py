"""
Script de valida√ß√£o do modelo ML.
Verifica overfitting e performance de generaliza√ß√£o.
"""

import numpy as np
import pandas as pd
import joblib
import os
from sklearn.model_selection import cross_val_score, train_test_split
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
from sklearn.ensemble import RandomForestRegressor


def load_model_and_data():
    """Carrega modelo e GERA dados de valida√ß√£o."""
    from train_model import generate_synthetic_data  # Import da fun√ß√£o
    
    model_path = os.path.join(os.path.dirname(__file__), 'model.pkl')
    model = joblib.load(model_path)
    
    # GERA 2000 amostras para valida√ß√£o (n√£o usa sample_data.csv)
    print("   Gerando dataset de valida√ß√£o (2000 amostras)...")
    df = generate_synthetic_data(n_samples=2000)
    
    return model, df


def validate_with_cross_validation(model, X, y, cv=5):
    """
    Valida√ß√£o cruzada para detectar overfitting.
    
    Se R¬≤ CV for muito menor que R¬≤ treino ‚Üí overfitting!
    """
    print("\n" + "="*60)
    print("üîÑ VALIDA√á√ÉO CRUZADA (Cross-Validation)")
    print("="*60)
    
    # Diferentes m√©tricas
    r2_scores = cross_val_score(model, X, y, cv=cv, scoring='r2')
    neg_mse_scores = cross_val_score(model, X, y, cv=cv, scoring='neg_mean_squared_error')
    neg_mae_scores = cross_val_score(model, X, y, cv=cv, scoring='neg_mean_absolute_error')
    
    # Converter negativos para positivos
    mse_scores = -neg_mse_scores
    mae_scores = -neg_mae_scores
    rmse_scores = np.sqrt(mse_scores)
    
    print(f"\nüìä Resultados ({cv}-fold CV):")
    print(f"   R¬≤ Score:  {r2_scores.mean():.4f} (¬± {r2_scores.std():.4f})")
    print(f"   RMSE:      {rmse_scores.mean():.2f} (¬± {rmse_scores.std():.2f})")
    print(f"   MAE:       {mae_scores.mean():.2f} (¬± {mae_scores.std():.2f})")
    
    print(f"\nüìà R¬≤ por fold:")
    for i, score in enumerate(r2_scores, 1):
        print(f"   Fold {i}: {score:.4f}")
    
    return {
        'r2_mean': r2_scores.mean(),
        'r2_std': r2_scores.std(),
        'rmse_mean': rmse_scores.mean(),
        'mae_mean': mae_scores.mean()
    }


def evaluate_on_holdout(model, X, y, test_size=0.2):
    """
    Avalia em conjunto de teste separado (hold-out).
    """
    print("\n" + "="*60)
    print("üß™ AVALIA√á√ÉO HOLD-OUT (Test Set)")
    print("="*60)
    
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size, random_state=42
    )
    
    # Predi√ß√µes
    y_train_pred = model.predict(X_train)
    y_test_pred = model.predict(X_test)
    
    # M√©tricas treino
    r2_train = r2_score(y_train, y_train_pred)
    rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))
    mae_train = mean_absolute_error(y_train, y_train_pred)
    
    # M√©tricas teste
    r2_test = r2_score(y_test, y_test_pred)
    rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))
    mae_test = mean_absolute_error(y_test, y_test_pred)
    
    print(f"\nüìä TREINO (80% dos dados):")
    print(f"   R¬≤ Score:  {r2_train:.4f}")
    print(f"   RMSE:      {rmse_train:.2f}")
    print(f"   MAE:       {mae_train:.2f}")
    
    print(f"\nüìä TESTE (20% dos dados):")
    print(f"   R¬≤ Score:  {r2_test:.4f}")
    print(f"   RMSE:      {rmse_test:.2f}")
    print(f"   MAE:       {mae_test:.2f}")
    
    # Diagn√≥stico de overfitting
    print(f"\nüîç DIAGN√ìSTICO:")
    diff = r2_train - r2_test
    print(f"   Diferen√ßa R¬≤ (treino - teste): {diff:.4f}")
    
    if diff > 0.10:
        print(f"   ‚ö†Ô∏è  OVERFITTING DETECTADO!")
        print(f"   ‚Üí Modelo memoriza treino mas n√£o generaliza bem")
    elif diff > 0.05:
        print(f"   ‚ö° Overfitting leve (aceit√°vel para MVP)")
    else:
        print(f"   ‚úÖ Boa generaliza√ß√£o!")
    
    return {
        'r2_train': r2_train,
        'r2_test': r2_test,
        'overfitting_gap': diff
    }


def check_feature_importance(model, feature_names):
    """Mostra features mais importantes."""
    print("\n" + "="*60)
    print("üéØ IMPORT√ÇNCIA DAS FEATURES")
    print("="*60)
    
    importance_df = pd.DataFrame({
        'feature': feature_names,
        'importance': model.feature_importances_
    }).sort_values('importance', ascending=False)
    
    print("\n")
    for _, row in importance_df.iterrows():
        bar = '‚ñà' * int(row['importance'] * 50)
        print(f"   {row['feature']:20s} {bar} {row['importance']:.4f}")
    
    return importance_df


def suggest_improvements(cv_results, holdout_results):
    """Sugere melhorias baseado nos resultados."""
    print("\n" + "="*60)
    print("üí° SUGEST√ïES DE MELHORIA")
    print("="*60)
    
    r2_cv = cv_results['r2_mean']
    overfitting_gap = holdout_results['overfitting_gap']
    
    suggestions = []
    
    # Verifica performance
    if r2_cv < 0.80:
        suggestions.append("‚ö†Ô∏è  R¬≤ CV baixo - considere:")
        suggestions.append("   ‚Ä¢ Coletar mais dados")
        suggestions.append("   ‚Ä¢ Adicionar features relevantes")
        suggestions.append("   ‚Ä¢ Testar outros algoritmos (XGBoost)")
    elif r2_cv >= 0.85:
        suggestions.append("‚úÖ R¬≤ CV excelente!")
    
    # Verifica overfitting
    if overfitting_gap > 0.10:
        suggestions.append("‚ö†Ô∏è  Overfitting significativo - ajustar:")
        suggestions.append("   ‚Ä¢ Reduzir max_depth (ex: 8 ou 6)")
        suggestions.append("   ‚Ä¢ Aumentar min_samples_split (ex: 10)")
        suggestions.append("   ‚Ä¢ Reduzir n_estimators")
        suggestions.append("   ‚Ä¢ Adicionar mais dados de treino")
    elif overfitting_gap > 0.05:
        suggestions.append("‚ö° Overfitting leve - monitorar mas aceit√°vel")
    else:
        suggestions.append("‚úÖ Sem overfitting detectado!")
    
    # Sugest√µes gerais
    suggestions.append("\nüìã Para produ√ß√£o, considere:")
    suggestions.append("   ‚Ä¢ Implementar monitoramento de data drift")
    suggestions.append("   ‚Ä¢ A/B testing com modelos alternativos")
    suggestions.append("   ‚Ä¢ Retreinamento peri√≥dico (ex: mensal)")
    suggestions.append("   ‚Ä¢ Valida√ß√£o com dados reais (n√£o sint√©ticos)")
    
    for suggestion in suggestions:
        print(suggestion)


def retrain_if_needed(X, y, current_model):
    """
    Se overfitting for detectado, retreina com regulariza√ß√£o.
    """
    print("\n" + "="*60)
    print("üîß RETREINAMENTO COM REGULARIZA√á√ÉO")
    print("="*60)
    
    print("\nTreinando modelo regularizado...")
    print("   Par√¢metros: max_depth=8, min_samples_split=10")
    
    regularized_model = RandomForestRegressor(
        n_estimators=100,
        max_depth=8,           # Reduzido de 10
        min_samples_split=10,  # Aumentado de 2
        random_state=42,
        n_jobs=-1
    )
    
    # Treina
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )
    regularized_model.fit(X_train, y_train)
    
    # Avalia
    y_train_pred = regularized_model.predict(X_train)
    y_test_pred = regularized_model.predict(X_test)
    
    r2_train = r2_score(y_train, y_train_pred)
    r2_test = r2_score(y_test, y_test_pred)
    
    print(f"\nüìä Resultados do modelo regularizado:")
    print(f"   R¬≤ Treino: {r2_train:.4f}")
    print(f"   R¬≤ Teste:  {r2_test:.4f}")
    print(f"   Gap:       {r2_train - r2_test:.4f}")
    
    # Cross-validation
    cv_scores = cross_val_score(regularized_model, X, y, cv=5, scoring='r2')
    print(f"   R¬≤ CV:     {cv_scores.mean():.4f} (¬± {cv_scores.std():.4f})")
    
    return regularized_model


def main():
    """Executa valida√ß√£o completa."""
    print("\n" + "="*60)
    print("üéØ VALIDA√á√ÉO DO MODELO - BENEFIT PREDICTOR")
    print("="*60)
    
    # 1. Carrega modelo e dados
    print("\nüìÇ Carregando modelo e dados...")
    model, df = load_model_and_data()
    
    X = df.drop('satisfaction_score', axis=1)
    y = df['satisfaction_score']
    feature_names = X.columns.tolist()
    
    print(f"   ‚úÖ Modelo carregado: {type(model).__name__}")
    print(f"   ‚úÖ Dados carregados: {len(df)} amostras, {len(feature_names)} features")
    
    # 2. Cross-validation
    cv_results = validate_with_cross_validation(model, X, y, cv=5)
    
    # 3. Hold-out test
    holdout_results = evaluate_on_holdout(model, X, y, test_size=0.2)
    
    # 4. Feature importance
    check_feature_importance(model, feature_names)
    
    # 5. Sugest√µes
    suggest_improvements(cv_results, holdout_results)
    
    # 6. Retreinamento se necess√°rio
    if holdout_results['overfitting_gap'] > 0.10:
        print("\n‚ö†Ô∏è  Overfitting detectado!")
        response = input("\n   Retreinar com regulariza√ß√£o? (s/n): ")
        
        if response.lower() == 's':
            new_model = retrain_if_needed(X, y, model)
            
            save = input("\n   Salvar modelo regularizado? (s/n): ")
            if save.lower() == 's':
                model_path = os.path.join(os.path.dirname(__file__), 'model.pkl')
                joblib.dump(new_model, model_path)
                print(f"\n   ‚úÖ Modelo salvo em: {model_path}")
    
    print("\n" + "="*60)
    print("‚úÖ VALIDA√á√ÉO COMPLETA!")
    print("="*60)


if __name__ == '__main__':
    main()